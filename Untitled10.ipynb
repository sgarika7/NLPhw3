{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g4ttyGlB2rI7"
      },
      "outputs": [],
      "source": [
        "#step 10: perturbate data for robustness study\n",
        "import random\n",
        "import re\n",
        "def perturbate_dev_data(dev_data):\n",
        "    def add_typo(sentence):\n",
        "        \"\"\"Introduce typos by replacing or swapping characters in a word.\"\"\"\n",
        "        words = sentence.split()\n",
        "        if not words:\n",
        "            return sentence\n",
        "        word_idx = random.randint(0, len(words) - 1)\n",
        "        char_idx = random.randint(0, len(words[word_idx]) - 1)\n",
        "        perturbed_word = (\n",
        "            words[word_idx][:char_idx]\n",
        "            + random.choice('abcdefghijklmnopqrstuvwxyz')\n",
        "            + words[word_idx][char_idx + 1:]\n",
        "        )\n",
        "        words[word_idx] = perturbed_word\n",
        "        return ' '.join(words)\n",
        "\n",
        "    def replace_with_synonym(sentence, synonyms_dict):\n",
        "        \"\"\"Replace some words with synonyms from a given dictionary.\"\"\"\n",
        "        words = sentence.split()\n",
        "        return ' '.join([synonyms_dict.get(word, word) for word in words])\n",
        "\n",
        "    def introduce_grammar_error(sentence):\n",
        "        \"\"\"Introduce grammar errors by modifying verb forms or tenses.\"\"\"\n",
        "        return re.sub(r'\\bis\\b', 'are', sentence)\n",
        "\n",
        "    def add_random_noise(sentence):\n",
        "        \"\"\"Insert random noise words into the sentence.\"\"\"\n",
        "        words = sentence.split()\n",
        "        noise_words = ['xx', 'yy', 'zz', random.choice('abcdefghijklmnopqrstuvwxyz')]\n",
        "        insert_pos = random.randint(0, len(words))\n",
        "        words.insert(insert_pos, random.choice(noise_words))\n",
        "        return ' '.join(words)\n",
        "\n",
        "    synonyms_dict = {\n",
        "        \"board\": \"plank\",\n",
        "        \"circulate\": \"distribute\",\n",
        "        \"hook\": \"catch\",\n",
        "        \"recreation\": \"leisure\",\n",
        "        \"domesticity\": \"homeliness\",\n",
        "        \"acquisition\": \"purchase\",\n",
        "        \"meeting\": \"gathering\",\n",
        "        \"nude\": \"bare\",\n",
        "        \"mark\": \"impression\",\n",
        "        \"association\": \"connection\",\n",
        "        \"inclination\": \"tendency\",\n",
        "        \"glaze\": \"coat\",\n",
        "        \"piggyback\": \"carry\",\n",
        "        \"pick\": \"choose\",\n",
        "        \"lecture\": \"talk\",\n",
        "        \"bondage\": \"captivity\",\n",
        "    }\n",
        "\n",
        "\n",
        "    perturbed_dev = dev_data.copy()\n",
        "    perturbed_dev[3] = perturbed_dev[3].apply(\n",
        "        lambda x: add_typo(introduce_grammar_error(replace_with_synonym(x, synonyms_dict)))\n",
        "    )\n",
        "    perturbed_dev[4] = perturbed_dev[4].apply(\n",
        "        lambda x: add_random_noise(introduce_grammar_error(add_typo(x)))\n",
        "    )\n",
        "\n",
        "    return perturbed_dev\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Perturb the dev dataset\n",
        "perturbed_dev_data = perturbate_dev_data(dev_data2)\n",
        "\n",
        "# Display a sample of the perturbed dev data\n",
        "print(perturbed_dev_data.info())\n",
        "perturbed_dev_data.head(15)\n",
        "\n"
      ],
      "metadata": {
        "id": "Q2FMd0lb2upQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "perturbed_dev_data['log2freq1'] = perturbed_dev_data[3].apply(lambda x: np.mean([\n",
        "    np.log2(record.get((token, 'NOUN', 'NON_STOP'), [1])[0])\n",
        "    for token in gensim.utils.simple_preprocess(x, min_len=2)\n",
        "]))\n",
        "\n",
        "perturbed_dev_data['log2freq2'] = perturbed_dev_data[4].apply(lambda x: np.mean([\n",
        "    np.log2(record.get((token, 'NOUN', 'NON_STOP'), [1])[0])\n",
        "    for token in gensim.utils.simple_preprocess(x, min_len=2)\n",
        "]))\n",
        "\n",
        "perturbed_dev_data['is_stop_word1'] = perturbed_dev_data[3].apply(lambda x: any(\n",
        "    token in stop_words for token in gensim.utils.simple_preprocess(x, min_len=2)\n",
        "))\n",
        "\n",
        "perturbed_dev_data['is_stop_word2'] = perturbed_dev_data[4].apply(lambda x: any(\n",
        "    token in stop_words for token in gensim.utils.simple_preprocess(x, min_len=2)\n",
        "))\n",
        "perturbed_dev_data['emb1'] = perturbed_dev_data[3].apply(lambda x: emb(x))\n",
        "perturbed_dev_data['emb2'] = perturbed_dev_data[4].apply(lambda x: emb(x))"
      ],
      "metadata": {
        "id": "7IMTApTZ2xNA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "perturbed_dev_data['cosine_similarity_discounted'] = perturbed_dev_data.apply(\n",
        "    lambda row: discounted_cosine_similarity(\n",
        "        row['emb1'], row['emb2'], row['log2freq1'], row['log2freq2'],\n",
        "        row['is_stop_word1'], row['is_stop_word2'], best_parameters\n",
        "    ),\n",
        "    axis=1\n",
        ")\n"
      ],
      "metadata": {
        "id": "0Cgh_L682z3m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "perturbed_dev_data['predictions'] = perturbed_dev_data['cosine_similarity_discounted'].apply(\n",
        "    lambda x: 'T' if x >= best_parameters['threshold'] else 'F'\n",
        ")\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "perturbed_accuracy = accuracy_score(dev_gold_labels, perturbed_dev_data['predictions'])\n",
        "print(f\"Discounted Accuracy on Perturbed Dev Set: {perturbed_accuracy:.2%}\")\n"
      ],
      "metadata": {
        "id": "7y6DhIeR24lw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "success_cases = perturbed_dev_data[perturbed_dev_data['predictions'] == dev_gold_labels]\n",
        "failure_cases = perturbed_dev_data[perturbed_dev_data['predictions'] != dev_gold_labels]\n",
        "\n",
        "print(\"Examples of Success Cases:\")\n",
        "print(success_cases.head(2))  # Display 2 success cases\n",
        "\n",
        "print(\"\\nExamples of Failure Cases:\")\n",
        "print(failure_cases.head(2))  # Display 2 failure cases\n"
      ],
      "metadata": {
        "id": "LnZU8fii25b3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "perturbed_recall = recall_score(dev_gold_labels, perturbed_dev_data['predictions'], pos_label='T')\n",
        "perturbed_f1 = f1_score(dev_gold_labels, perturbed_dev_data['predictions'], pos_label='T')\n",
        "\n",
        "print(\"Perturbed Dev Set Metrics:\")\n",
        "print(f\"Recall: {perturbed_recall:.2%}\")\n",
        "print(f\"F1-Score: {perturbed_f1:.2%}\\n\")\n",
        "\n",
        "\n",
        "# Confusion Matrix for Perturbed Dev Set\n",
        "cm_perturbed = confusion_matrix(dev_gold_labels, perturbed_dev_data['predictions'], labels=['T', 'F'])  # Use actual labels\n",
        "disp_perturbed = ConfusionMatrixDisplay(confusion_matrix=cm_perturbed, display_labels=['T (Similar)', 'F (Different)'])\n",
        "disp_perturbed.plot(cmap='Oranges')\n",
        "plt.title('Confusion Matrix (Perturbed Dev Set)')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "WyErC5LO277T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cUNeyWjg3CkX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}